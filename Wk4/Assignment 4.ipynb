{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-data-analysis/resources/0dhYG) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Hypothesis Testing\n",
    "This assignment requires more individual learning than previous assignments - you are encouraged to check out the [pandas documentation](http://pandas.pydata.org/pandas-docs/stable/) to find functions or methods you might not have used yet, or ask questions on [Stack Overflow](http://stackoverflow.com/) and tag them as pandas and python related. And of course, the discussion forums are open for interaction with your peers and the course staff.\n",
    "\n",
    "Definitions:\n",
    "* A _quarter_ is a specific three month period, Q1 is January through March, Q2 is April through June, Q3 is July through September, Q4 is October through December.\n",
    "* A _recession_ is defined as starting with two consecutive quarters of GDP decline, and ending with two consecutive quarters of GDP growth.\n",
    "* A _recession bottom_ is the quarter within a recession which had the lowest GDP.\n",
    "* A _university town_ is a city which has a high percentage of university students compared to the total population of the city.\n",
    "\n",
    "**Hypothesis**: University towns have their mean housing prices less effected by recessions. Run a t-test to compare the ratio of the mean price of houses in university towns the quarter before the recession starts compared to the recession bottom. (`price_ratio=quarter_before_recession/recession_bottom`)\n",
    "\n",
    "The following data files are available for this assignment:\n",
    "* From the [Zillow research data site](http://www.zillow.com/research/data/) there is housing data for the United States. In particular the datafile for [all homes at a city level](http://files.zillowstatic.com/research/public/City/City_Zhvi_AllHomes.csv), ```City_Zhvi_AllHomes.csv```, has median home sale prices at a fine grained level.\n",
    "* From the Wikipedia page on college towns is a list of [university towns in the United States](https://en.wikipedia.org/wiki/List_of_college_towns#College_towns_in_the_United_States) which has been copy and pasted into the file ```university_towns.txt```.\n",
    "* From Bureau of Economic Analysis, US Department of Commerce, the [GDP over time](http://www.bea.gov/national/index.htm#gdp) of the United States in current dollars (use the chained value in 2009 dollars), in quarterly intervals, in the file ```gdplev.xls```. For this assignment, only look at GDP data from the first quarter of 2000 onward.\n",
    "\n",
    "Each function in this assignment below is worth 10%, with the exception of ```run_ttest()```, which is worth 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this dictionary to map state names to two letter acronyms\n",
    "states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', 'WY': 'Wyoming', 'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', 'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', 'MT': 'Montana', 'IL': 'Illinois', 'TN': 'Tennessee', 'DC': 'District of Columbia', 'VT': 'Vermont', 'ID': 'Idaho', 'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii', 'WI': 'Wisconsin', 'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', 'AZ': 'Arizona', 'GU': 'Guam', 'MS': 'Mississippi', 'PR': 'Puerto Rico', 'NC': 'North Carolina', 'TX': 'Texas', 'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', 'IA': 'Iowa', 'MO': 'Missouri', 'CT': 'Connecticut', 'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana', 'KS': 'Kansas', 'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', 'CA': 'California', 'CO': 'Colorado', 'PA': 'Pennsylvania', 'DE': 'Delaware', 'NM': 'New Mexico', 'RI': 'Rhode Island', 'MN': 'Minnesota', 'VI': 'Virgin Islands', 'NH': 'New Hampshire', 'MA': 'Massachusetts', 'GA': 'Georgia', 'ND': 'North Dakota', 'VA': 'Virginia'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGDPData():\n",
    "\n",
    "    gdplev = pd.read_excel(\"../course1_downloads/gdplev.xls\", header=0, names=[\"Quarter\",\"GDP in billions of current dollars\", \"GDP in billions of chained 2009 dollars\"], usecols=\"E:G\", skiprows=7)\n",
    "\n",
    "    gdp_data = pd.DataFrame(data=gdplev.iloc[-(2 + 16 * 4):])\n",
    "\n",
    "    gdp_data = gdp_data.reset_index(drop=True)\n",
    "\n",
    "    gdp_data = gdp_data.set_index(gdp_data.index)\n",
    "\n",
    "    return gdp_data\n",
    "\n",
    "\n",
    "def readHousingData():\n",
    "\n",
    "    arr_slice = slice(0, 6)         # [0,6]; 0:6 is [0,6)\n",
    "    us_home_prices = pd.read_csv(\n",
    "        \"../course1_downloads/City_Zhvi_AllHomes.csv\", sep=\"\\n\", header=0, delimiter=\",\")\n",
    "\n",
    "    us_home_prices = pd.DataFrame(\n",
    "        data=us_home_prices, columns=us_home_prices.columns[arr_slice].append(us_home_prices.columns[-(12 * 16 + 8):]))\n",
    "\n",
    "    us_home_prices.iloc[:, -(12 * 16 + 8):].apply(pd.to_numeric, axis=1)\n",
    "\n",
    "    # Substitute the names of \"State\" for their full names\n",
    "    for idx, stname in enumerate(us_home_prices[\"State\"]):\n",
    "        full_stname = states.get(stname)       \n",
    "        us_home_prices.at[idx, \"State\"] = full_stname\n",
    "\n",
    "\n",
    "    return us_home_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_university_towns():\n",
    "    '''Returns a DataFrame of towns and the states they are in from the \n",
    "    university_towns.txt list. The format of the DataFrame should be:\n",
    "    DataFrame( [ [\"Michigan\", \"Ann Arbor\"], [\"Michigan\", \"Yipsilanti\"] ], \n",
    "    columns=[\"State\", \"RegionName\"]  )\n",
    "    \n",
    "    The following cleaning needs to be done:\n",
    "\n",
    "    1. For \"State\", removing characters from \"[\" to the end.\n",
    "    2. For \"RegionName\", when applicable, removing every character from \" (\" to the end.\n",
    "    3. Depending on how you read the data, you may need to remove newline character '\\n'. '''\n",
    "    \n",
    "    # Read in the data first, then separate the data by state names\n",
    "    state_pattern = re.compile(pattern=\"^.*\\[edit\\]$\")\n",
    "    states_and_regions = []\n",
    "    with open(\"../course1_downloads/university_towns.txt\", 'r', encoding='utf-8') as uni_towns:\n",
    "        uni_towns.seek(0)\n",
    "        curr_state = \"\"\n",
    "\n",
    "        # Read the data line by line, deal with state and region names separately\n",
    "        for line in uni_towns:\n",
    "            if(re.match(state_pattern,line)):\n",
    "                curr_state = line[0:line.find('[')]\n",
    "            elif(line.find(\"(\")): \n",
    "                # region = line[0:line.find('(') - 1].rstrip('\\s') # Remove any extra whitespace chars on the right-hand side\n",
    "                region = line[0:line.find('(') - 1]\n",
    "                state_and_region = []\n",
    "                state_and_region.append(curr_state)\n",
    "                state_and_region.append(region)\n",
    "                states_and_regions.append(state_and_region)\n",
    "        \n",
    "    # Organize the data in \"[[State, RegionName], ...]\" format\n",
    "    # ans = pd.DataFrame(data=states_and_regions, columns=[\"State\", \"RegionName\"], dtype=str).groupby(['State']).agg('size')\n",
    "    ans = pd.DataFrame(data=states_and_regions, columns=[\"State\", \"RegionName\"], dtype=str)\n",
    "    # index = ans.columns\n",
    "    # ans = ans.reset_index().set_index(index)\n",
    "    # ans.index = ans[\"State\"]\n",
    "    # print(ans.head())\n",
    "    # print(\"# of university towns: {}\".format(len(ans)))\n",
    "    return ans\n",
    "\n",
    "# df = get_list_of_university_towns()\n",
    "# print(df.where(df['State'] == \"New Hampshire\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'2008q2'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recession_start():\n",
    "    '''Returns the year and quarter of the recession start time as a \n",
    "    string value in a format such as 2005q3'''\n",
    "\n",
    "    ### A recession is defined as starting with two consecutive quarters of GDP decline, and ending with two consecutive quarters of GDP growth. \n",
    "    \n",
    "    gdp_data = readGDPData()\n",
    "\n",
    "    # print(gdp_data.head())\n",
    "\n",
    "    ans = \"\"\n",
    "\n",
    "    for i in range(len(gdp_data) - 2):\n",
    "        if(float(gdp_data.loc[i].loc['GDP in billions of chained 2009 dollars']) - float(gdp_data.loc[i + 1].loc['GDP in billions of chained 2009 dollars']) > 0 and float(gdp_data.loc[i + 1].loc['GDP in billions of chained 2009 dollars']) - float(gdp_data.loc[i + 2].loc['GDP in billions of chained 2009 dollars']) > 0): # Use the data under column 'GDP in billions of chained 2009 dollars' as it only takes into account the inflation from 2009 onwards\n",
    "            ans = gdp_data.loc[i].Quarter\n",
    "            break\n",
    "\n",
    "    # print(gdp_data.loc[gdp_data['Quarter'] == '2008q3'])\n",
    "    # print(gdp_data.loc[gdp_data['Quarter'] == '2008q4'])\n",
    "    # print(gdp_data.loc[gdp_data['Quarter'] == '2009q1'])\n",
    "    # return \"ANSWER\"\n",
    "    return ans\n",
    "\n",
    "get_recession_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'2009q4'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recession_end():\n",
    "    '''Returns the year and quarter of the recession end time as a \n",
    "    string value in a format such as 2005q3'''\n",
    "    \n",
    "    # A recession is defined as starting with two consecutive quarters of GDP decline, and ending with two consecutive quarters of GDP growth.\n",
    "\n",
    "    gdp_data = readGDPData()\n",
    "\n",
    "    recsn_start = get_recession_start() # How to determine the recession start? Determine by column \"GDP in billions of current dollars\" or \"GDP in billions of chained 2009 dollars\"?\n",
    "\n",
    "    rescn_start_idx = gdp_data[gdp_data['Quarter'] == recsn_start].index.values[0]\n",
    "\n",
    "    # print(rescn_start_idx.values)\n",
    "\n",
    "    gdp_data_after_recsn_began = gdp_data.iloc[rescn_start_idx + 2:] # Here the starting index is 2 because the shortest duration of a recession is 3 quarters (2 consecutive quarters) \n",
    "\n",
    "    gdp_data_after_recsn_began = gdp_data_after_recsn_began.reset_index(drop=True)\n",
    "\n",
    "    # print(gdp_data_after_recsn_began.head())\n",
    "\n",
    "    ans = \"ANSWER\"\n",
    "\n",
    "    for i in range(len(gdp_data_after_recsn_began) - 2): \n",
    "        if(float(gdp_data_after_recsn_began.loc[i].loc['GDP in billions of chained 2009 dollars']) - float(gdp_data_after_recsn_began.loc[i + 1].loc['GDP in billions of chained 2009 dollars']) < 0 and float(gdp_data_after_recsn_began.loc[i + 1].loc['GDP in billions of chained 2009 dollars']) - float(gdp_data_after_recsn_began.loc[i + 2].loc['GDP in billions of chained 2009 dollars']) < 0):\n",
    "            ans =  gdp_data_after_recsn_began.loc[i + 2].Quarter\n",
    "            break\n",
    "    return ans\n",
    "\n",
    "get_recession_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'2009q2'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recession_bottom():\n",
    "    '''Returns the year and quarter of the recession bottom time as a \n",
    "    string value in a format such as 2005q3'''\n",
    "    # A recession bottom is the quarter within a recession which had the lowest GDP.\n",
    "    gdp_data = readGDPData()\n",
    "\n",
    "    recsn_start = get_recession_start()\n",
    "\n",
    "    recsn_end = get_recession_end()\n",
    "\n",
    "    recsn_start_idx = gdp_data[gdp_data.Quarter == recsn_start].index.values[0]\n",
    "    # recsn_start_idx = gdp_data[gdp_data.Quarter == recsn_start].index\n",
    "\n",
    "    # print(recsn_start_idx)\n",
    "\n",
    "    recsn_end_idx = gdp_data[gdp_data.Quarter == recsn_end].index.values[0]\n",
    "    # recsn_end_idx = gdp_data[gdp_data.Quarter == recsn_end].index\n",
    "    \n",
    "    # print(recsn_end_idx)\n",
    "    \n",
    "    gdp_data_in_recsn = gdp_data[recsn_start_idx:recsn_end_idx + 1]\n",
    "\n",
    "    # print(gdp_data_in_recsn)    \n",
    "\n",
    "    ans = \"ANSWER\"\n",
    "    \n",
    "    bottom_val = np.min(gdp_data_in_recsn['GDP in billions of current dollars'])\n",
    "\n",
    "    # print(bottom_val)\n",
    "\n",
    "    ans = gdp_data_in_recsn[gdp_data_in_recsn['GDP in billions of current dollars'] == bottom_val].loc[:,'Quarter'] # Series\n",
    "\n",
    "    ans = ans.iloc[0] # String\n",
    "\n",
    "    return ans\n",
    "\n",
    "get_recession_bottom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarterMapper(date_str):\n",
    "    if not type(date_str) == str:\n",
    "        return date_str\n",
    "    \n",
    "    if not date_str.startswith(\"20\"):\n",
    "        return date_str\n",
    "\n",
    "    mappings = {\n",
    "        (\"01\",\"02\",\"03\"): \"q1\",\n",
    "        (\"04\",\"05\",\"06\"): \"q2\",\n",
    "        (\"07\",\"08\",\"09\"): \"q3\",\n",
    "        (\"10\",\"11\",\"12\"): \"q4\",\n",
    "    }\n",
    "    year = date_str[0:4]\n",
    "    month = date_str[-2:]\n",
    "    ans = \"\"\n",
    "    for key_strs in mappings.keys():\n",
    "        quarter = \"\"\n",
    "        for key_str in key_strs:\n",
    "            if key_str == month:\n",
    "                quarter = mappings.get(key_strs)\n",
    "                break\n",
    "        if not quarter == \"\":\n",
    "            # ans = \"\".join([year,quarter])\n",
    "            ans = pd.Period(\"\".join([year,quarter]))\n",
    "            break\n",
    "            \n",
    "    return ans\n",
    "\n",
    "def convert_housing_data_to_quarters():\n",
    "    '''Converts the housing data to quarters and returns it as mean \n",
    "    values in a dataframe. This dataframe should be a dataframe with\n",
    "    columns for 2000q1 through 2016q3, and should have a multi-index\n",
    "    in the shape of [\"State\",\"RegionName\"].\n",
    "    \n",
    "    Note: Quarters are defined in the assignment description, they are\n",
    "    not arbitrary three month periods.\n",
    "    \n",
    "    The resulting dataframe should have 67 columns, and 10,730 rows.\n",
    "    '''\n",
    "    housing_data = readHousingData()\n",
    "\n",
    "    # Map the months to quarters\n",
    "\n",
    "    # housing_data = (housing_data.groupby(\"State\")\n",
    "    #                             .agg({\"State\":\"size\"})\n",
    "    # )\n",
    "\n",
    "    # housing_data = housing_data.reset_index().iloc[:, 7:len(housing_data.columns)]\n",
    "\n",
    "    housing_data = housing_data.reset_index()\n",
    "\n",
    "    # housing_data = housing_data.rename(quarterMapper, axis='columns')\n",
    "\n",
    "    housing_data = housing_data.rename(quarterMapper, axis='columns')\n",
    "\n",
    "    # housing_data.set_index([\"State\", \"RegionName\"], inplace=True)\n",
    "    # print(housing_data.head())\n",
    "\n",
    "    # Need to change the data of housing prices to numeric data first\n",
    "    # housing_data_by_quarters = housing_data.groupby(level=0, axis=1).agg('mean')\n",
    "    housing_data_by_quarters = housing_data.iloc[:, -(12 * 16 + 8):].groupby(level=0, axis=1).agg('mean')\n",
    "\n",
    "    # housing_data_by_quarters.apply(lambda x:x, axis=1)\n",
    "\n",
    "    # print(housing_data_by_quarters.head())\n",
    "    housing_data_by_quarters['State'] = housing_data['State']\n",
    "    housing_data_by_quarters['RegionName'] = housing_data['RegionName']\n",
    "\n",
    "\n",
    "    # index = pd.MultiIndex.from_frame()\n",
    "    housing_data_by_quarters = housing_data_by_quarters.reset_index(drop=True).set_index(['State', 'RegionName'])\n",
    "\n",
    "    # ans = pd.DataFrame(data=housing_data_by_quarters, index=['State', 'RegionName'])\n",
    "\n",
    "    # print(housing_data_by_quarters)\n",
    "\n",
    "    ans = housing_data_by_quarters\n",
    "    # print(ans.head())\n",
    "\n",
    "    return ans\n",
    "\n",
    "# convert_housing_data_to_quarters().xs(('Alabama','Auburn'))\n",
    "\n",
    "# quarterMapper(\"2010-01\")\n",
    "# quarterMapper(\"2010-04\")\n",
    "# quarterMapper(\"2010-08\")\n",
    "# quarterMapper(\"2010-11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ttest():\n",
    "    '''First creates new data showing the decline or growth of housing prices\n",
    "    between the recession start and the recession bottom. Then runs a ttest\n",
    "    comparing the university town values to the non-university towns values, \n",
    "    return whether the alternative hypothesis (that the two groups are the same)\n",
    "    is true or not as well as the p-value of the confidence. \n",
    "    \n",
    "    Return the tuple (different, p, better) where different=True if the t-test is\n",
    "    True at a p<0.01 (we reject the null hypothesis), or different=False if \n",
    "    otherwise (we cannot reject the null hypothesis). The variable p should\n",
    "    be equal to the exact p value returned from scipy.stats.ttest_ind(). The\n",
    "    value for better should be either \"university town\" or \"non-university town\"\n",
    "    depending on which has a lower mean price ratio (which is equivilent to a\n",
    "    reduced market loss).'''\n",
    "    \n",
    "    housing_data = convert_housing_data_to_quarters()\n",
    "\n",
    "    uni_towns = get_list_of_university_towns()\n",
    "\n",
    "    # print(\"uni towns in California: {}\".format(uni_towns[uni_towns.State == 'California']))\n",
    "\n",
    "    st_and_reg_in_uni_towns = [uni_towns['State'], uni_towns['RegionName']]\n",
    "\n",
    "    tuples = list(zip(*st_and_reg_in_uni_towns))\n",
    "    # housing_data_of_uni_towns = housing_data.query(\"@housing_data['RegionName'] == @uni_towns\")\n",
    "    \n",
    "    # print(uni_towns.head())\n",
    "\n",
    "    # print(housing_data.xs(\"RegionName\").head())\n",
    "\n",
    "    # quarters_from_recession_start_to_bottom = [get_recession_start(), '2008q3', '2008q4', '2009q1', get_recession_bottom()]\n",
    "\n",
    "    start = pd.Period(get_recession_start())\n",
    "\n",
    "    bottom = pd.Period(get_recession_bottom())\n",
    "\n",
    "    quarters_from_recession_start_to_bottom = [start,bottom]\n",
    "\n",
    "    # print(repr(quarters_from_recession_start_to_bottom))\n",
    "    # housing_data_of_uni_towns = housing_data[housing_data['RegionName'] == uni_towns]\n",
    "\n",
    "    # print(housing_data_of_uni_towns.head())\n",
    "\n",
    "    ### Get the housing prices btn the recession start and bottom\n",
    "    housing_data_during_recession = housing_data.loc[:, quarters_from_recession_start_to_bottom]\n",
    "    \n",
    "    # housing_data_during_recession['ratio'] = housing_data.loc[:, start - 1] / housing_data.loc[:, bottom]\n",
    "\n",
    "    housing_data_during_recession['ratio'] = housing_data.loc[:, start - 1] / housing_data.loc[:, bottom]\n",
    "\n",
    "    # print(housing_data_during_recession['ratio'])\n",
    "    # print(housing_data_during_recession.head())\n",
    "    ### Acquire the data for uni-towns during that period\n",
    "    \n",
    "    uni_towns_data = None\n",
    "\n",
    "    # uni_towns_data = pd.merge(uni_towns, housing_data_during_recession, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "    # print(len(uni_towns_data)) # 1059\n",
    "\n",
    "    # uni_towns_data = None\n",
    "\n",
    "    non_uni_towns_data = housing_data_during_recession\n",
    "\n",
    "    for tup in tuples:\n",
    "        try:\n",
    "            # print(housing_data_during_recession.xs(tup))\n",
    "            tup_data = housing_data_during_recession.xs(tup)\n",
    "        except:\n",
    "            # Ignore errors here\n",
    "            continue\n",
    "        tup_data = housing_data_during_recession.xs(tup)\n",
    "        if(type(uni_towns_data) == type(None)):\n",
    "            uni_towns_data = pd.DataFrame(data=tup_data)\n",
    "        else:\n",
    "            uni_towns_data = uni_towns_data.append(tup_data)\n",
    "        non_uni_towns_data = non_uni_towns_data.drop(tup_data.index.values)\n",
    "    # print(len(uni_towns_data)) # 269\n",
    "    # print(len(non_uni_towns_data)) # 10461\n",
    "    ### Acquire the data for non-uni towns during that period\n",
    "    # print(uni_towns_data.head(10))\n",
    "    # print(non_uni_towns_data.xs(('Alabama', 'Montevallo')))\n",
    "\n",
    "    # Run the t-test and get the p-value\n",
    "    # print(uni_towns_data.reset_index()[get_recession_start()])\n",
    "    # print(non_uni_towns_data.reset_index()[get_recession_start()])\n",
    "    # price_diff_uni_towns = uni_towns_data.loc[:, start] - uni_towns_data.loc[:, bottom]\n",
    "    # price_diff_non_uni_towns = non_uni_towns_data.loc[:, start] - non_uni_towns_data.loc[:, bottom]\n",
    "    # print(price_diff_uni_towns.head())\n",
    "    # print(price_diff_non_uni_towns.head())\n",
    "    # _,p = ttest_ind(price_diff_uni_towns, price_diff_non_uni_towns, nan_policy='omit')\n",
    "    _,p = ttest_ind(uni_towns_data.ratio, non_uni_towns_data.ratio, nan_policy='omit')\n",
    "    # print(p)\n",
    "    # # Compute the mean price ratio and determine which is the better\n",
    "    difference = (True if p < 0.01 else False)\n",
    "    mean_ratio_uni_towns = uni_towns_data.ratio.mean()\n",
    "    mean_ratio_non_uni_towns = non_uni_towns_data.ratio.mean()\n",
    "    better = (\"university town\" if mean_ratio_uni_towns - mean_ratio_non_uni_towns < 0 else \"non-university town\")\n",
    "    return (difference, p, better)\n",
    "    # return \"ANSWER\"\n",
    "\n",
    "run_ttest()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-data-analysis",
   "graded_item_id": "Il9Fx",
   "launcher_item_id": "TeDW0",
   "part_id": "WGlun"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}